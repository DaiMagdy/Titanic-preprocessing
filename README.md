# Titanic Preprocessing & ML Pipeline

## ğŸš€ Key Components and Data Flow

The system's **modular design** centers around the `my_preprocessing.py` function library, which provides reusable preprocessing operations orchestrated by `main.py` for **batch processing** or imported directly for **interactive use**.

| ğŸ§© **Component**           | ğŸ¯ **Purpose**                  | ğŸ›  **Key Functions**                              | ğŸ“¦ **Output Artifacts**      |
|----------------------------|---------------------------------|---------------------------------------------------|------------------------------|
| ğŸ“„ `titanic.csv`           | Raw dataset                     | Data source                                       | 891 passenger records        |
| âš™ï¸ `my_preprocessing.py`   | Function library                 | `read_data`, `check_types`, `visual`, `encode_columns` | Reusable preprocessing       |
| ğŸ–¥ `main.py`                | Pipeline orchestrator            | Workflow coordination, logging                    | `output.txt`, `plots/`       |
| ğŸ““ `Titanic.ipynb`         | Complete ML pipeline             | End-to-end analysis                               | `submission.csv`             |

---

### ğŸ” Data Quality and Transformation Pipeline
This section covers **data validation**, **cleaning**, and **feature transformation** to ensure consistent, high-quality inputs for the ML model.

---

## ğŸ“Š Data Flow Diagram

```mermaid
flowchart LR
    A[ğŸ“„ titanic.csv<br>Raw Dataset] --> B[âš™ï¸ my_preprocessing.py<br>Preprocessing Functions]
    B --> C[ğŸ–¥ main.py<br>Pipeline Orchestration]
    C --> D[ğŸ“Š Plots / ğŸ“œ output.txt]
    C --> E[ğŸ““ Titanic.ipynb<br>ML Pipeline]
    E --> F[ğŸ“¦ submission.csv<br>Final Output]
```
Øµ